{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7nniMeGgurgFGYKTeNLE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amosweckstrom/neural_networks/blob/main/mnist_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Neural Network to predict if an handwritten character is a 0 or a 1\n",
        "\n",
        "## Decription:\n",
        "\n",
        " Dataset:\n",
        " - The classic mnist dataset is used. But all the handwritten characters  except for the 0s and 1s are removed\n",
        " - We have two datasets, the mnist_test.csv and the mnist_train_small.csv\n",
        "\n",
        "\n",
        "\n",
        " Neural Network:\n",
        "\n",
        " - I used the logistic regression as the activation functions for the units/neurons which uses a sigmoid function to map predictions between 0 and 1\n",
        "\n",
        " - To calculate the loss for binary values we use the BinaryCrossEntropy loss function\n",
        "\n",
        " - I created 3 layers for the network\n",
        "   \n",
        "   Layer 1: 25 neurons\\\n",
        "   Layer 2: 15 neurons\\\n",
        "   Layer 3 (Output Layer): 1 neuron\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6d1v4RIK6Ot9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jKKOkk9_Y-21"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import data\n",
        "df = pd.read_csv(\"./sample_data/mnist_train_small.csv\")\n",
        "df_test = pd.read_csv(\"./sample_data/mnist_test.csv\")"
      ],
      "metadata": {
        "id": "mN3yJ5xvZhnn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Data"
      ],
      "metadata": {
        "id": "1pNdKfgSBPcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect the training data\n",
        "print(\"Data dimensions:\", df.shape)\n",
        "print(\"Data type:\", type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4GJmCWTcwch",
        "outputId": "606ed9e9-8911-4d4c-9861-217be65e4eb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dimensions: (19999, 785)\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new dataframe where only the handwritten 0s and 1s are\n",
        "df_1_0 = df[(df[\"6\"] == 1) | (df[\"6\"] == 0)]\n",
        "\n",
        "#Create training data by dropping the target data column\n",
        "X_train = df_1_0.drop(\"6\", axis=1)\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "#Create target data\n",
        "y_train = df_1_0[\"6\"]\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(\n",
        "    \"Dimensions of the training data:\", X_train.shape,\n",
        "    \"\\nData type:\", type(y_train)\n",
        "\n",
        "    )\n",
        "print(\n",
        "    \"Dimensions of the target data:\", y_train.shape ,\n",
        "    \"\\nData type:\", type(y_train)\n",
        "\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52lE6ypfbTwP",
        "outputId": "135fb9d6-5c9a-4f98-de8f-e15912fa2303"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of the training data: (4205, 784) \n",
            "Data type: <class 'numpy.ndarray'>\n",
            "Dimensions of the target data: (4205,) \n",
            "Data type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data"
      ],
      "metadata": {
        "id": "iid_0B-cA21T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect the test data\n",
        "print(\"Data dimensions:\", df_test.shape)\n",
        "print(\"Data type:\", type(df_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9JIxJzsA4_u",
        "outputId": "093c32db-1105-4edb-8df5-ede3eb247507"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dimensions: (9999, 785)\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_1_0 = df_test[(df_test[\"7\"] == 1) | (df_test[\"7\"] == 0)]\n",
        "\n",
        "X_test = df_test_1_0.drop(\"7\", axis=1)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "y_test = df_test_1_0[\"7\"]\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(\n",
        "    \"Dimensions of the test feature data:\", X_train.shape,\n",
        "    \"\\nData type:\", type(y_train)\n",
        "\n",
        "    )\n",
        "print(\n",
        "    \"Dimensions of the test target data:\", y_train.shape ,\n",
        "    \"\\nData type:\", type(y_train)\n",
        "\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20QvvEnoBbEL",
        "outputId": "a8c08d06-7651-4568-9986-267d03170914"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of the test feature data: (4205, 784) \n",
            "Data type: <class 'numpy.ndarray'>\n",
            "Dimensions of the test target data: (4205,) \n",
            "Data type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network initialization and training"
      ],
      "metadata": {
        "id": "XlwniczyGxQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize a Sequential Neural network with sigmoid activation function\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(5, activation=\"sigmoid\"),\n",
        "    Dense(3, activation=\"sigmoid\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "])\n",
        "\n",
        "#Set model loss function to BinaryCrossEntropy to get the errors of binary predictions and targets\n",
        "model.compile(loss=BinaryCrossentropy())"
      ],
      "metadata": {
        "id": "ISL_S-akbkAK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the neural network\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpLKvt36ccLX",
        "outputId": "86fe05ec-4990-46e6-cb9b-80b7a1f5089e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "132/132 [==============================] - 1s 2ms/step - loss: 0.6022\n",
            "Epoch 2/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.5073\n",
            "Epoch 3/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.4298\n",
            "Epoch 4/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.3554\n",
            "Epoch 5/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.2900\n",
            "Epoch 6/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.2347\n",
            "Epoch 7/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.1889\n",
            "Epoch 8/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.1521\n",
            "Epoch 9/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.1227\n",
            "Epoch 10/10\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7926ce7571c0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predictions"
      ],
      "metadata": {
        "id": "89rolRmZG100"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions on the test data\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "#Apply a threshhold of 0.5 so that the predictions are binary\n",
        "predictions = (pred >= 0.5).astype(int).flatten()\n",
        "\n",
        "print(\n",
        "    \"\\n\"\n",
        "    \"Predictions:\", predictions,\n",
        "    \"\\nDimensions of the predictions array:\", predictions.shape\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"\\n\",\n",
        "    \"Target values:\", y_test,\n",
        "    \"\\nDimensions of the target values\", y_test.shape\n",
        ")\n",
        "\n",
        "print(\"\\nLooks good!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXkZ_r36yvzh",
        "outputId": "dd0f3e60-9888-46c2-a985-8a59954e4904"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 0s 2ms/step\n",
            "\n",
            "Predictions: [1 0 1 ... 1 0 1] \n",
            "Dimensions of the predictions array: (2115,)\n",
            "\n",
            " Target values: [1 0 1 ... 1 0 1] \n",
            "Dimensions of the target values (2115,)\n",
            "\n",
            "Looks good!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a function that calculates the accuracy of our predictions\n",
        "\n",
        "def calculate_accuracy(predictions, actuals):\n",
        "\n",
        "    predicitons = list(predictions)\n",
        "    actuals = list(actuals)\n",
        "    # Check that the two lists are of the same length\n",
        "    if len(predictions) != len(actuals):\n",
        "        raise ValueError(\"The lengths of the prediction and actual lists must be the same.\")\n",
        "\n",
        "    # Count the number of correct predictions\n",
        "    correct_predictions = sum(pred == actual for pred, actual in zip(predictions, actuals))\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    accuracy = correct_predictions / len(predictions)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "4mnizA2O0wuU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    \"Model Accuracy:\",\n",
        "    calculate_accuracy(predictions, y_test)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIV7mX1Q1gYQ",
        "outputId": "131658bd-52f9-4d04-b172-2881946b462e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9995271867612293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Olnl58Zt1kC3"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}